[{'gen_model': 'DeepSeek_8B_SFT', 'reward_model': 'Deepseek_8B', 'train_set': 'v1', 'pearson_all': 0.11866251616264255, 'spearman_all': 0.11658193252489045}, {'gen_model': 'DeepSeek_8B_SFT', 'reward_model': 'Deepseek_8B', 'train_set': 'expneg', 'pearson_all': 0.1812945047650365, 'spearman_all': 0.17929406164288267}, {'gen_model': 'DeepSeek_8B_SFT', 'reward_model': 'Deepseek_8B', 'train_set': 'exppos', 'pearson_all': 0.12008186253505441, 'spearman_all': 0.18302760755562944}, {'gen_model': 'DeepSeek_8B_SFT', 'reward_model': 'Deepseek_8B', 'train_set': 'normal', 'pearson_all': 0.10275723856072472, 'spearman_all': 0.09806058892042117}, {'gen_model': 'DeepSeek_8B_SFT', 'reward_model': 'Deepseek_8B', 'train_set': 'uniform', 'pearson_all': 0.07053744343726742, 'spearman_all': 0.0851642429164419}, {'gen_model': 'DeepSeek_8B_SFT', 'reward_model': 'Llama3.1_8B', 'train_set': 'v1', 'pearson_all': -0.08281943715031645, 'spearman_all': -0.09511648376663145}, {'gen_model': 'DeepSeek_8B_SFT', 'reward_model': 'Llama3.1_8B', 'train_set': 'expneg', 'pearson_all': 0.1196968976832461, 'spearman_all': 0.11968261477561513}, {'gen_model': 'DeepSeek_8B_SFT', 'reward_model': 'Llama3.1_8B', 'train_set': 'exppos', 'pearson_all': 0.10740864243340688, 'spearman_all': 0.13666856264875288}, {'gen_model': 'DeepSeek_8B_SFT', 'reward_model': 'Llama3.1_8B', 'train_set': 'normal', 'pearson_all': 0.13040505677859943, 'spearman_all': 0.18601841136105496}, {'gen_model': 'DeepSeek_8B_SFT', 'reward_model': 'Llama3.1_8B', 'train_set': 'uniform', 'pearson_all': 0.1439729666971619, 'spearman_all': 0.16178332025888795}, {'gen_model': 'DeepSeek_8B_SFT', 'reward_model': 'Qwen3_8B', 'train_set': 'v1', 'pearson_all': 0.11024013199063876, 'spearman_all': 0.13416831319631392}, {'gen_model': 'DeepSeek_8B_SFT', 'reward_model': 'Qwen3_8B', 'train_set': 'expneg', 'pearson_all': 0.21043660471144643, 'spearman_all': 0.2095555872518685}, {'gen_model': 'DeepSeek_8B_SFT', 'reward_model': 'Qwen3_8B', 'train_set': 'exppos', 'pearson_all': 0.20831096848272385, 'spearman_all': 0.2221021148109996}, {'gen_model': 'DeepSeek_8B_SFT', 'reward_model': 'Qwen3_8B', 'train_set': 'normal', 'pearson_all': 0.2808837384506013, 'spearman_all': 0.26444562182040066}, {'gen_model': 'DeepSeek_8B_SFT', 'reward_model': 'Qwen3_8B', 'train_set': 'uniform', 'pearson_all': 0.19506339643242246, 'spearman_all': 0.21208567484151394}, {'gen_model': 'Llama3.1_8B_SFT', 'reward_model': 'Deepseek_8B', 'train_set': 'v1', 'pearson_all': 0.01388347464982792, 'spearman_all': 0.0005966016524485093}, {'gen_model': 'Llama3.1_8B_SFT', 'reward_model': 'Deepseek_8B', 'train_set': 'expneg', 'pearson_all': 0.18530176464683115, 'spearman_all': 0.18843577258980299}, {'gen_model': 'Llama3.1_8B_SFT', 'reward_model': 'Deepseek_8B', 'train_set': 'exppos', 'pearson_all': -0.0008502531108822782, 'spearman_all': 0.029885014727521846}, {'gen_model': 'Llama3.1_8B_SFT', 'reward_model': 'Deepseek_8B', 'train_set': 'normal', 'pearson_all': 0.1269866934389205, 'spearman_all': 0.08851877536465325}, {'gen_model': 'Llama3.1_8B_SFT', 'reward_model': 'Deepseek_8B', 'train_set': 'uniform', 'pearson_all': 0.11696632175672295, 'spearman_all': 0.09115606248380187}, {'gen_model': 'Llama3.1_8B_SFT', 'reward_model': 'Llama3.1_8B', 'train_set': 'v1', 'pearson_all': 0.04947529224135993, 'spearman_all': -0.001236612115820252}, {'gen_model': 'Llama3.1_8B_SFT', 'reward_model': 'Llama3.1_8B', 'train_set': 'expneg', 'pearson_all': 0.12624667054483055, 'spearman_all': 0.14163557155814901}, {'gen_model': 'Llama3.1_8B_SFT', 'reward_model': 'Llama3.1_8B', 'train_set': 'exppos', 'pearson_all': 3.246064045657192e-05, 'spearman_all': 0.06196789638914122}, {'gen_model': 'Llama3.1_8B_SFT', 'reward_model': 'Llama3.1_8B', 'train_set': 'normal', 'pearson_all': 0.08884166472785979, 'spearman_all': 0.10447086716223962}, {'gen_model': 'Llama3.1_8B_SFT', 'reward_model': 'Llama3.1_8B', 'train_set': 'uniform', 'pearson_all': 0.020910899723579675, 'spearman_all': 0.055188339193508025}, {'gen_model': 'Llama3.1_8B_SFT', 'reward_model': 'Qwen3_8B', 'train_set': 'v1', 'pearson_all': 0.12088195745221852, 'spearman_all': 0.16641907154109545}, {'gen_model': 'Llama3.1_8B_SFT', 'reward_model': 'Qwen3_8B', 'train_set': 'expneg', 'pearson_all': 0.14015379164637776, 'spearman_all': 0.20696706982110208}, {'gen_model': 'Llama3.1_8B_SFT', 'reward_model': 'Qwen3_8B', 'train_set': 'exppos', 'pearson_all': 0.006498227086682312, 'spearman_all': 0.09585510637243619}, {'gen_model': 'Llama3.1_8B_SFT', 'reward_model': 'Qwen3_8B', 'train_set': 'normal', 'pearson_all': 0.07328049742217715, 'spearman_all': 0.16837698813998328}, {'gen_model': 'Llama3.1_8B_SFT', 'reward_model': 'Qwen3_8B', 'train_set': 'uniform', 'pearson_all': 0.12596295554720272, 'spearman_all': 0.2285756378894932}, {'gen_model': 'Qwen3_8B_SFT', 'reward_model': 'Deepseek_8B', 'train_set': 'v1', 'pearson_all': -0.0705446495873883, 'spearman_all': -0.0882282638404287}, {'gen_model': 'Qwen3_8B_SFT', 'reward_model': 'Deepseek_8B', 'train_set': 'expneg', 'pearson_all': 0.11181819658515804, 'spearman_all': 0.13099833779947775}, {'gen_model': 'Qwen3_8B_SFT', 'reward_model': 'Deepseek_8B', 'train_set': 'exppos', 'pearson_all': 0.12972665767769642, 'spearman_all': 0.20113588569969917}, {'gen_model': 'Qwen3_8B_SFT', 'reward_model': 'Deepseek_8B', 'train_set': 'normal', 'pearson_all': 0.06988194899607704, 'spearman_all': 0.079131474493168}, {'gen_model': 'Qwen3_8B_SFT', 'reward_model': 'Deepseek_8B', 'train_set': 'uniform', 'pearson_all': 0.09517049501913709, 'spearman_all': 0.12583908631132756}, {'gen_model': 'Qwen3_8B_SFT', 'reward_model': 'Llama3.1_8B', 'train_set': 'v1', 'pearson_all': -0.172040632078046, 'spearman_all': -0.19799610179951377}, {'gen_model': 'Qwen3_8B_SFT', 'reward_model': 'Llama3.1_8B', 'train_set': 'expneg', 'pearson_all': 0.07021351473886692, 'spearman_all': 0.05940698961354362}, {'gen_model': 'Qwen3_8B_SFT', 'reward_model': 'Llama3.1_8B', 'train_set': 'exppos', 'pearson_all': 0.15267045556893535, 'spearman_all': 0.1723119449549199}, {'gen_model': 'Qwen3_8B_SFT', 'reward_model': 'Llama3.1_8B', 'train_set': 'normal', 'pearson_all': 0.08501010256117282, 'spearman_all': 0.06466076814725598}, {'gen_model': 'Qwen3_8B_SFT', 'reward_model': 'Llama3.1_8B', 'train_set': 'uniform', 'pearson_all': 0.07338486648920481, 'spearman_all': 0.07961644592365326}, {'gen_model': 'Qwen3_8B_SFT', 'reward_model': 'Qwen3_8B', 'train_set': 'v1', 'pearson_all': 0.09269456975855635, 'spearman_all': 0.11970576889015748}, {'gen_model': 'Qwen3_8B_SFT', 'reward_model': 'Qwen3_8B', 'train_set': 'expneg', 'pearson_all': 0.11031457594145726, 'spearman_all': 0.13505765208654988}, {'gen_model': 'Qwen3_8B_SFT', 'reward_model': 'Qwen3_8B', 'train_set': 'exppos', 'pearson_all': 0.10042197411353551, 'spearman_all': 0.14189299782315662}, {'gen_model': 'Qwen3_8B_SFT', 'reward_model': 'Qwen3_8B', 'train_set': 'normal', 'pearson_all': 0.07217465367648553, 'spearman_all': 0.13490225428926086}, {'gen_model': 'Qwen3_8B_SFT', 'reward_model': 'Qwen3_8B', 'train_set': 'uniform', 'pearson_all': 0.09082779723225697, 'spearman_all': 0.1479410256651487}]